{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "585b3f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, RFE\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "import warnings\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "plt.style.use('seaborn-v0_8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cba63bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (9706, 21)\n",
      "Test data shape: (1624, 21)\n",
      "Training period: 2002 - 2020\n",
      "Test period: 2021 - 2023\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv('nfl_train_data_2002_2020.csv')\n",
    "test_data = pd.read_csv('nfl_test_data_2021_2024.csv')\n",
    "\n",
    "print(f\"Training data shape: {train_data.shape}\")\n",
    "print(f\"Test data shape: {test_data.shape}\")\n",
    "print(f\"Training period: {train_data['season'].min():.0f} - {train_data['season'].max():.0f}\")\n",
    "print(f\"Test period: {test_data['season'].min():.0f} - {test_data['season'].max():.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21605162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the feaures we determined to be important in feature engineering\n",
    "X_features = [\n",
    "    'off_1st_down', 'off_pass_yds', 'off_rush_yds', 'off_total_yds', 'off_turnovers',\n",
    "    'def_1st_down', 'def_pass_yds', 'def_rush_yds', 'def_total_yds', 'def_turnovers', \n",
    "    'home', 'wins', 'losses', 'overtime'\n",
    "]\n",
    "\n",
    "y_target = 'outcome'\n",
    "\n",
    "\n",
    "missing_train = [f for f in X_features if f not in train_data.columns]\n",
    "missing_test = [f for f in X_features if f not in test_data.columns]\n",
    "\n",
    "if missing_train:\n",
    "    print(f\"\\nMissing features in training data: {missing_train}\")\n",
    "if missing_test:\n",
    "    print(f\"\\nMissing features in test data: {missing_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4fba4fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATA PREPARATION SUMMARY ===\n",
      "Training features shape: (9706, 14)\n",
      "Training target shape: (9706,)\n",
      "Test features shape: (1624, 14)\n",
      "Test target shape: (1624,)\n",
      "\n",
      "Missing values in training features: 0\n",
      "Missing values in test features: 0\n"
     ]
    }
   ],
   "source": [
    "X_train = train_data[X_features].copy()\n",
    "y_train = train_data[y_target].copy()\n",
    "X_test = test_data[X_features].copy()\n",
    "y_test = test_data[y_target].copy()\n",
    "\n",
    "print(\"=== DATA PREPARATION SUMMARY ===\")\n",
    "print(f\"Training features shape: {X_train.shape}\")\n",
    "print(f\"Training target shape: {y_train.shape}\")\n",
    "print(f\"Test features shape: {X_test.shape}\")\n",
    "print(f\"Test target shape: {y_test.shape}\")\n",
    "\n",
    "print(f\"\\nMissing values in training features: {X_train.isnull().sum().sum()}\")\n",
    "print(f\"Missing values in test features: {X_test.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba89027e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n= 6: Train=0.7922, Test=0.7950 - Top features: ['off_1st_down', 'off_turnovers', 'def_1st_down']\n",
      "n= 7: Train=0.7935, Test=0.7937 - Top features: ['off_1st_down', 'off_turnovers', 'def_1st_down']\n",
      "n= 8: Train=0.7935, Test=0.7937 - Top features: ['off_1st_down', 'off_turnovers', 'def_1st_down']\n",
      "n= 9: Train=0.8070, Test=0.7943 - Top features: ['off_1st_down', 'off_rush_yds', 'off_turnovers']\n",
      "n=10: Train=0.8153, Test=0.7937 - Top features: ['off_1st_down', 'off_rush_yds', 'off_turnovers']\n",
      "n=11: Train=0.8159, Test=0.7956 - Top features: ['off_1st_down', 'off_rush_yds', 'off_turnovers']\n",
      "n=12: Train=0.8199, Test=0.7962 - Top features: ['off_1st_down', 'off_rush_yds', 'off_total_yds']\n",
      "n=13: Train=0.8204, Test=0.7962 - Top features: ['off_1st_down', 'off_pass_yds', 'off_rush_yds']\n",
      "n=14: Train=0.8197, Test=0.7962 - Top features: ['off_1st_down', 'off_pass_yds', 'off_rush_yds']\n",
      "\n",
      "BEST STEPWISE MODEL: 12 features, 0.7962 (79.62%) accuracy\n",
      "\n",
      "=== OPTIMAL FEATURE SET (12 features) ===\n",
      "   1. off_1st_down    (coef:  0.0417)\n",
      "   2. off_rush_yds    (coef:  0.0100)\n",
      "   3. off_total_yds   (coef:  0.0052)\n",
      "   4. off_turnovers   (coef: -0.8718)\n",
      "   5. def_1st_down    (coef: -0.0508)\n",
      "   6. def_rush_yds    (coef: -0.0097)\n",
      "   7. def_total_yds   (coef: -0.0052)\n",
      "   8. def_turnovers   (coef:  0.8667)\n",
      "   9. home            (coef:  0.5797)\n",
      "  10. wins            (coef:  0.0943)\n",
      "  11. losses          (coef: -0.0945)\n",
      "  12. overtime        (coef:  0.0208)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# We want can cut down features more using RFE\n",
    "best_accuracy = 0\n",
    "best_n_features = 14\n",
    "best_features = X_features.copy()\n",
    "results = []\n",
    "\n",
    "for n_features in range(6, 15):  # Test 6-14 features\n",
    "    # Use RFE with logistic regression\n",
    "    rfe = RFE(\n",
    "        estimator=LogisticRegression(solver='liblinear', C=1.0, random_state=42),\n",
    "        n_features_to_select=n_features,\n",
    "        step=1\n",
    "    )\n",
    "    \n",
    "    X_train_rfe = rfe.fit_transform(X_train, y_train)\n",
    "    X_test_rfe = rfe.transform(X_test)\n",
    "    \n",
    "    # This will train the model on a subset of features\n",
    "    model_rfe = LogisticRegression(solver='liblinear', C=1.0, random_state=42)\n",
    "    model_rfe.fit(X_train_rfe, y_train)\n",
    "    \n",
    "    train_acc = accuracy_score(y_train, model_rfe.predict(X_train_rfe))\n",
    "    test_acc = accuracy_score(y_test, model_rfe.predict(X_test_rfe))\n",
    "    \n",
    "    selected_features = [X_features[i] for i in range(len(X_features)) if rfe.support_[i]]\n",
    "    \n",
    "    results.append({\n",
    "        'n_features': n_features,\n",
    "        'train_acc': train_acc,\n",
    "        'test_acc': test_acc,\n",
    "        'selected_features': selected_features,\n",
    "        'model': model_rfe,\n",
    "        'rfe': rfe\n",
    "    })\n",
    "    \n",
    "    print(f\"n={n_features:2d}: Train={train_acc:.4f}, Test={test_acc:.4f} - Top features: {selected_features[:3]}\")\n",
    "    \n",
    "    if test_acc > best_accuracy:\n",
    "        best_accuracy = test_acc\n",
    "        best_n_features = n_features\n",
    "        best_features = selected_features\n",
    "\n",
    "print(f\"\\nBEST STEPWISE MODEL: {best_n_features} features, {best_accuracy:.4f} ({best_accuracy*100:.2f}%) accuracy\")\n",
    "\n",
    "best_result = [r for r in results if r['n_features'] == best_n_features][0]\n",
    "print(f\"\\n=== OPTIMAL FEATURE SET ({best_n_features} features) ===\")\n",
    "for i, feature in enumerate(best_result['selected_features'], 1):\n",
    "    coef = best_result['model'].coef_[0][i-1]\n",
    "    print(f\"  {i:2d}. {feature:15s} (coef: {coef:7.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ab3c977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as: nfl_logistic_model_v1.pkl\n",
      "     Variable  Coefficient  Abs_Coefficient Impact\n",
      "off_turnovers      -0.8718           0.8718   High\n",
      "def_turnovers       0.8667           0.8667   High\n",
      "         home       0.5797           0.5797   High\n",
      "       losses      -0.0945           0.0945 Medium\n",
      "         wins       0.0943           0.0943 Medium\n",
      " def_1st_down      -0.0508           0.0508 Medium\n",
      " off_1st_down       0.0417           0.0417    Low\n",
      "     overtime       0.0208           0.0208    Low\n",
      " off_rush_yds       0.0100           0.0100    Low\n",
      " def_rush_yds      -0.0097           0.0097    Low\n",
      "def_total_yds      -0.0052           0.0052    Low\n",
      "off_total_yds       0.0052           0.0052    Low\n",
      "Final accuracy: 79.6%\n"
     ]
    }
   ],
   "source": [
    "final_model = best_result['model']\n",
    "final_features = best_result['selected_features']\n",
    "final_rfe = best_result['rfe']\n",
    "\n",
    "model_filename = 'nfl_logistic_model_v1.pkl'\n",
    "with open(model_filename, 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'model': final_model,\n",
    "        'features': final_features,\n",
    "        'rfe_selector': final_rfe,\n",
    "        'feature_order': X_features,\n",
    "        'performance': {\n",
    "            'train_accuracy': best_result['train_acc'],\n",
    "            'test_accuracy': best_result['test_acc'],\n",
    "            'n_features': best_result['n_features']\n",
    "        }\n",
    "    }, f)\n",
    "\n",
    "print(f\"Model saved as: {model_filename}\")\n",
    "\n",
    "# Detailed coefficient analysis to show important features\n",
    "coef_analysis = pd.DataFrame({\n",
    "    'Variable': final_features,\n",
    "    'Coefficient': final_model.coef_[0],\n",
    "    'Abs_Coefficient': np.abs(final_model.coef_[0]),\n",
    "    'Impact': ['High' if abs(c) > 0.5 else 'Medium' if abs(c) > 0.05 else 'Low' \n",
    "              for c in final_model.coef_[0]]\n",
    "}).sort_values('Abs_Coefficient', ascending=False)\n",
    "\n",
    "print(coef_analysis.to_string(index=False, float_format='%.4f'))\n",
    "\n",
    "print(f\"Final accuracy: {best_result['test_acc']:.1%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21d3747e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete dataset shape: (11330, 21)\n",
      "Period covered: 2002 - 2023\n",
      "Total games: 11,330\n",
      "\n",
      "Feature matrix shape: (11330, 12)\n",
      "Target vector shape: (11330,)\n",
      "Missing values: 0\n",
      "Win rate: 0.500\n"
     ]
    }
   ],
   "source": [
    "# Now we want to train the final model on the entire dset \n",
    "complete_data = pd.read_csv('nfl_game_features_2002_2024.csv')\n",
    "\n",
    "print(f\"Complete dataset shape: {complete_data.shape}\")\n",
    "print(f\"Period covered: {complete_data['season'].min():.0f} - {complete_data['season'].max():.0f}\")\n",
    "print(f\"Total games: {complete_data.shape[0]:,}\")\n",
    "\n",
    "X_complete = complete_data[final_features].copy()  # Use optimal features from stepwise selection\n",
    "y_complete = complete_data[y_target].copy()\n",
    "\n",
    "print(f\"\\nFeature matrix shape: {X_complete.shape}\")\n",
    "print(f\"Target vector shape: {y_complete.shape}\")\n",
    "print(f\"Missing values: {X_complete.isnull().sum().sum()}\")\n",
    "print(f\"Win rate: {y_complete.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2247b6fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy on complete dataset: 0.8160 (81.60%)\n",
      "Stepwise model (validation): 0.7962 (79.62%)\n",
      "Production model (complete):  0.8160 (81.60%)\n",
      "\n",
      "=== PRODUCTION MODEL COEFFICIENTS ===\n",
      "     Variable  Coefficient  Abs_Coefficient\n",
      "off_turnovers      -0.8862           0.8862\n",
      "def_turnovers       0.8754           0.8754\n",
      "         home       0.5197           0.5197\n",
      "       losses      -0.0934           0.0934\n",
      "         wins       0.0902           0.0902\n",
      " def_1st_down      -0.0532           0.0532\n",
      " off_1st_down       0.0431           0.0431\n",
      " off_rush_yds       0.0092           0.0092\n",
      " def_rush_yds      -0.0089           0.0089\n",
      "     overtime       0.0084           0.0084\n",
      "def_total_yds      -0.0058           0.0058\n",
      "off_total_yds       0.0056           0.0056\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Use the same configuration as the optimal stepwise model\n",
    "production_model = LogisticRegression(\n",
    "    solver='liblinear', \n",
    "    C=1.0, \n",
    "    random_state=42,\n",
    "    max_iter=1000\n",
    ")\n",
    "\n",
    "# Train on complete dataset with optimal features\n",
    "production_model.fit(X_complete, y_complete)\n",
    "\n",
    "# Calculate training accuracy on complete dataset\n",
    "y_complete_pred = production_model.predict(X_complete)\n",
    "complete_accuracy = accuracy_score(y_complete, y_complete_pred)\n",
    "\n",
    "print(f\"Training accuracy on complete dataset: {complete_accuracy:.4f} ({complete_accuracy*100:.2f}%)\")\n",
    "\n",
    "\n",
    "print(f\"Stepwise model (validation): {best_result['test_acc']:.4f} ({best_result['test_acc']*100:.2f}%)\")\n",
    "print(f\"Production model (complete):  {complete_accuracy:.4f} ({complete_accuracy*100:.2f}%)\")\n",
    "\n",
    "print(f\"\\n=== PRODUCTION MODEL COEFFICIENTS ===\")\n",
    "production_coef_analysis = pd.DataFrame({\n",
    "    'Variable': final_features,\n",
    "    'Coefficient': production_model.coef_[0],\n",
    "    'Abs_Coefficient': np.abs(production_model.coef_[0])\n",
    "}).sort_values('Abs_Coefficient', ascending=False)\n",
    "\n",
    "print(production_coef_analysis.to_string(index=False, float_format='%.4f'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5b837e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "production_model_filename = 'nfl_production_model_2002_2024.pkl'\n",
    "with open(production_model_filename, 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'model': production_model,\n",
    "        'features': final_features,\n",
    "        'feature_order': X_features,\n",
    "        'training_period': f\"{complete_data['season'].min():.0f}-{complete_data['season'].max():.0f}\",\n",
    "        'performance': {\n",
    "            'training_accuracy': complete_accuracy,\n",
    "            'training_samples': X_complete.shape[0],\n",
    "            'n_features': len(final_features)\n",
    "        },\n",
    "        'coefficients': {\n",
    "            'variables': final_features,\n",
    "            'values': production_model.coef_[0].tolist()\n",
    "        },\n",
    "        'metadata': {\n",
    "            'trained_date': pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            'solver': production_model.solver,\n",
    "            'regularization': production_model.C,\n",
    "            'random_state': production_model.random_state\n",
    "        }\n",
    "    }, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
